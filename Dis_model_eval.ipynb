{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import time\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import gensim\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('DiSmldata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, axes = plt.subplots(figsize=(20,7))\n",
    "ax = sns.countplot(x=df[\"label\"], palette=\"OrRd_r\")\n",
    "ax.set(title=\"Distribution of Product Ratings\", \\\n",
    "       xlabel=\"Sentiment\", ylabel=\"Sentiment Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words = ENGLISH_STOP_WORDS.union(['disneyland','tokyo','disney', 'im', 'tdrnow','paris','california','amp','disneysea','got',\n",
    "                                         '¬∫c', '¬∫f', '¬∫o¬∫','ùóßùóµùó≤','„Åè„Åæ„ÅÆ„Éó„Éº„Åï„Çì', '„Éá„Ç£„Ç∫„Éã„Éº', '„Éá„Ç£„Ç∫„Éã„Éº„Ç∑„Éº','„Éá„Ç£„Ç∫„Éã„Éº„Éè„É≠„Ç¶„Ç£„Éº„É≥',\n",
    "                                         '„Éá„Ç£„Ç∫„Éã„Éº„É©„É≥„Éâ', '„Éá„Ç£„Ç∫„Éã„ÉºÂ•Ω„Åç„Å®Áπã„Åå„Çä„Åü„ÅÑ', '„Éï„Çß„Çπ„ÉÜ„Ç£„Éê„É´„Ç™„Éñ„Éü„Çπ„ÉÜ„Ç£„Éº„ÇØ', '„Éû„É´„Éû„É≥',\n",
    "                                         '„Öã„Öã„Öã', 'Â†¥ÊâÄ', 'Êõ¥Êñ∞', 'Êúàreleased', 'Êù±‰∫¨„Éá„Ç£„Ç∫„Éã„Éº„Ç∑„Éº', 'Êù±‰∫¨„Éá„Ç£„Ç∫„Éã„Éº„É©„É≥„Éâ', 'Êù±‰∫¨„Éá„Ç£„Ç∫„Éã„Éº„É™„Çæ„Éº„Éà',\n",
    "                                         'È¶ôÊ∏ØËø™Â£´Â∞ºÊ®ÇÂúí', '¬∫¬∫', 'hong', 'kong',\"disneylandresort\", \"disneyland\", \"disneyresort\",\n",
    "                                          \"californiaadventure\",'downtowndisney','disneyanaheim','disneylandanaheim',\n",
    "                                          'disneycalifornia','californiadisney','disneysea', 'disneytokyo', 'disneytokyoresort', \n",
    "                                          'tokyodisney','tokyodisneyresort', 'tokyodisneyland','Êù±‰∫¨„Éá„Ç£„Ç∫„Éã„Éº„É©„É≥„Éâ', '„Éá„Ç£„Ç∫„Éã„Éº„É©„É≥„Éâ',\n",
    "                                          'Êù±‰∫¨„Éá„Ç£„Ç∫„Éã„Éº„Ç∑„Éº', '„Ç∫„Éã„Éº„Ç∑„Éº', 'tdr_now', 'tdr_md','tdr','dca','dl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['hash_count', 'emoji_count','clean_text',\n",
    "                                                        'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']], df['label'],test_size =0.20, random_state = 77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count vectorizer Document term matrix\n",
    "count_vect = CountVectorizer(stop_words = my_stop_words, min_df = 3, max_df = 50)\n",
    "count_vect_fit = count_vect.fit(X_train['clean_text'])\n",
    "\n",
    "count_train = count_vect_fit.transform(X_train['clean_text'])\n",
    "count_test = count_vect_fit.transform(X_test['clean_text'])\n",
    "\n",
    "X_train_vect = pd.concat([X_train[['hash_count', 'emoji_count', 'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']].reset_index(drop=True), \n",
    "           pd.DataFrame(count_train.toarray())], axis=1)\n",
    "X_test_vect = pd.concat([X_test[['hash_count', 'emoji_count', 'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']].reset_index(drop=True), \n",
    "           pd.DataFrame(count_test.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70008, 12029)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 23522), (1, 23522), (2, 23522), (3, 23522), (4, 23522), (5, 23522)]\n"
     ]
    }
   ],
   "source": [
    "#Balance the Data \n",
    "ros = RandomOverSampler(random_state=77)\n",
    "X_resampled_ros, y_resampled_ros = ros.fit_resample(X_train_vect.values, y_train.values)\n",
    "print(sorted(Counter(y_resampled_ros).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 5982), (1, 5982), (2, 5982), (3, 5982), (4, 5982), (5, 5982)]\n"
     ]
    }
   ],
   "source": [
    "X_resampled_ros_test, y_resampled_ros_test = ros.fit_resample(X_test_vect.values, y_test.values)\n",
    "print(sorted(Counter(y_resampled_ros_test).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 719.459 / Predict time: 5.263 ---- Precision: 0.528 / Recall: 0.493 / Accuracy: 0.493\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "#Instantiate our model \n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=1000, n_jobs=-1)\n",
    "\n",
    "#Model Fit \n",
    "start = time.time()\n",
    "rf.fit(X_resampled_ros, y_resampled_ros)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = rf.predict(X_resampled_ros_test)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_ros_test, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_resampled_ros_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1355676226213802, 'tweet_len'),\n",
       " (0.06981465925893084, 'cap_count'),\n",
       " (0.06160885541980688, 'punc_count'),\n",
       " (0.04983365735000892, 'hash_count'),\n",
       " (0.02588826210923301, 'joy'),\n",
       " (0.02482664727491569, 'sadness'),\n",
       " (0.022244452728189482, 'emoji_count'),\n",
       " (0.019968127916541976, 'fear'),\n",
       " (0.018719362934182426, 'anticipation'),\n",
       " (0.01675342786142678, 'anger'),\n",
       " (0.015328056959726938, 'disgust'),\n",
       " (0.01524454533328769, 'trust'),\n",
       " (0.011318434836613203, 'surprise'),\n",
       " (0.0008697401680626791, 3638),\n",
       " (0.0008291998036010272, 6213),\n",
       " (0.0008277462158314285, 10826),\n",
       " (0.0008061685178150136, 10052),\n",
       " (0.0007768196630855878, 2632),\n",
       " (0.0007207657655482084, 7524),\n",
       " (0.0007068535968719075, 2360)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest tells our Feature Importances\n",
    "importances = rf.feature_importances_\n",
    "(sorted(zip(importances, X_train_vect.columns), reverse=True))[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 596.526 / Predict time: 6.169 ---- Precision: 0.494 / Recall: 0.491 / Accuracy: 0.491\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Bayes\n",
    "\n",
    "#Instantiate our model \n",
    "nb_clf = MultinomialNB()\n",
    "\n",
    "#Train our Model \n",
    "start = time.time()\n",
    "nb_clf.fit(X_resampled_ros, y_resampled_ros)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = nb_clf.predict(X_resampled_ros_test)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_ros_test, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), \n",
    "    round(recall, 3), round((y_pred==y_resampled_ros_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justin/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 861.007 / Predict time: 3.461 ---- Precision: 0.42 / Recall: 0.414 / Accuracy: 0.414\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression \n",
    "\n",
    "#Instantiate our model\n",
    "lr = LogisticRegression(max_iter = 100, solver = 'lbfgs')\n",
    "\n",
    "#Train our Model\n",
    "start = time.time()\n",
    "lr.fit(X_resampled_ros, y_resampled_ros)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = lr.predict(X_resampled_ros_test)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_ros_test, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), \n",
    "    round((y_pred==y_resampled_ros_test).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF vector DTM\n",
    "tfidf_vect = TfidfVectorizer(stop_words = my_stop_words, min_df = 3, max_df = 50)\n",
    "tfidf_vect_fit = tfidf_vect.fit(X_train['clean_text'])\n",
    "\n",
    "tfidf_train = tfidf_vect_fit.transform(X_train['clean_text'])\n",
    "tfidf_test = tfidf_vect_fit.transform(X_test['clean_text'])\n",
    "\n",
    "X_train_vect_tf = pd.concat([X_train[['hash_count', 'emoji_count', 'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_train.toarray())], axis=1)\n",
    "X_test_vect_tf = pd.concat([X_test[['hash_count', 'emoji_count', 'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']].reset_index(drop=True), \n",
    "           pd.DataFrame(tfidf_test.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70008, 12029)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vect_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 23522), (1, 23522), (2, 23522), (3, 23522), (4, 23522), (5, 23522)]\n"
     ]
    }
   ],
   "source": [
    "#Balance the Data \n",
    "ros = RandomOverSampler(random_state=77) \n",
    "X_resampled_ros_tf, y_resampled_ros_tf = ros.fit_resample(X_train_vect_tf.values, y_train.values)\n",
    "print(sorted(Counter(y_resampled_ros_tf).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 5982), (1, 5982), (2, 5982), (3, 5982), (4, 5982), (5, 5982)]\n"
     ]
    }
   ],
   "source": [
    "X_resampled_ros_test_tf, y_resampled_ros_test_tf = ros.fit_resample(X_test_vect_tf.values, y_test.values)\n",
    "print(sorted(Counter(y_resampled_ros_test_tf).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 712.098 / Predict time: 7.252 ---- Precision: 0.526 / Recall: 0.491 / Accuracy: 0.491\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "#Instantiate our model \n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=1000, n_jobs=-1)\n",
    "\n",
    "#Model Fit \n",
    "start = time.time()\n",
    "rf.fit(X_resampled_ros_tf, y_resampled_ros_tf)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = rf.predict(X_resampled_ros_test_tf)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_ros_test_tf, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_resampled_ros_test_tf).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.13348286106624357, 'tweet_len'),\n",
       " (0.06675093458904073, 'cap_count'),\n",
       " (0.06187580467148789, 'punc_count'),\n",
       " (0.0499041330696658, 'hash_count'),\n",
       " (0.026270729450527608, 'joy'),\n",
       " (0.025620086296029947, 'sadness'),\n",
       " (0.021539711901196627, 'emoji_count'),\n",
       " (0.02129386218552071, 'fear'),\n",
       " (0.018340592860136274, 'anticipation'),\n",
       " (0.014659223551072288, 'trust'),\n",
       " (0.014280392810640028, 'anger'),\n",
       " (0.014154633767097847, 'disgust'),\n",
       " (0.010524613610567531, 'surprise'),\n",
       " (0.0008712632223012992, 6213),\n",
       " (0.0008554590915700229, 10052),\n",
       " (0.0008364796935487842, 2360),\n",
       " (0.0008124037843868159, 7524),\n",
       " (0.0008037226752877644, 2632),\n",
       " (0.000754955124494401, 5147),\n",
       " (0.0007525454628223672, 3638)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest tells our Feature Importances\n",
    "importances = rf.feature_importances_\n",
    "(sorted(zip(importances, X_train_vect_tf.columns), reverse=True))[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 32.631 / Predict time: 3.374 ---- Precision: 0.481 / Recall: 0.48 / Accuracy: 0.48\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Bayes\n",
    "\n",
    "#Instantiate our model \n",
    "nb_clf = MultinomialNB()\n",
    "\n",
    "#Train our Model \n",
    "start = time.time()\n",
    "nb_clf.fit(X_resampled_ros_tf, y_resampled_ros_tf)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = nb_clf.predict(X_resampled_ros_test_tf)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_ros_test_tf, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_resampled_ros_test_tf).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justin/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 916.527 / Predict time: 3.67 ---- Precision: 0.434 / Recall: 0.418 / Accuracy: 0.418\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression \n",
    "\n",
    "#Instantiate our model\n",
    "lr = LogisticRegression(max_iter = 100, solver = 'lbfgs')\n",
    "\n",
    "#Train our Model\n",
    "start = time.time()\n",
    "lr.fit(X_resampled_ros_tf, y_resampled_ros_tf)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = lr.predict(X_resampled_ros_test_tf)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_ros_test_tf, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_resampled_ros_test_tf).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_tweet = df.clean_text.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14986172, 17727920)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v = gensim.models.Word2Vec(\n",
    "            tokenized_tweet,\n",
    "            size=6000, # desired no. of features/independent variables \n",
    "            window=3, # context window size\n",
    "            min_count=3,\n",
    "            sg = 1, # 1 for skip-gram model\n",
    "            seed = 77)\n",
    "\n",
    "model_w2v.train(tokenized_tweet, total_examples= len(df['clean_text']), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('onkyo', 0.5513042211532593),\n",
       " ('hfplayer', 0.5392124652862549),\n",
       " ('khzbit', 0.5306228995323181),\n",
       " ('linemusic', 0.518783688545227),\n",
       " ('japantrip', 0.5057321190834045),\n",
       " ('japantravel', 0.5039234161376953),\n",
       " ('songsinfo', 0.495866596698761),\n",
       " ('deiscavaly', 0.48634207248687744),\n",
       " ('disneylandtokyo', 0.4860280156135559),\n",
       " ('disneysea', 0.4855746030807495)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(\"tokyo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('frightful', 0.3735705614089966),\n",
       " ('downloaded', 0.3665778636932373),\n",
       " ('enjoyable', 0.36242324113845825),\n",
       " ('funner', 0.3620840013027191),\n",
       " ('teens', 0.36068132519721985),\n",
       " ('bestfriends', 0.35546189546585083),\n",
       " ('bff', 0.35439085960388184),\n",
       " ('inappropriate', 0.34669607877731323),\n",
       " ('lingering', 0.34374797344207764),\n",
       " ('cabalcade', 0.34368300437927246)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(\"fun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('anaheimresort', 0.38957226276397705),\n",
       " ('internship', 0.38845300674438477),\n",
       " ('indigo', 0.3835405707359314),\n",
       " ('sanitation', 0.3835158348083496),\n",
       " ('kaboom', 0.37532806396484375),\n",
       " ('ymca', 0.37469249963760376),\n",
       " ('janitorial', 0.37304434180259705),\n",
       " ('disneycaliforniaadventurepark', 0.3703966736793518),\n",
       " ('disneydrinks', 0.36837852001190186),\n",
       " ('losangeles', 0.36001330614089966)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(\"anaheim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('serotonin', 0.5254299640655518),\n",
       " ('rioter', 0.5173180103302002),\n",
       " ('ahah', 0.5021933317184448),\n",
       " ('sht', 0.5005996823310852),\n",
       " ('commie', 0.4991770386695862),\n",
       " ('hating', 0.49500101804733276),\n",
       " ('succession', 0.48815059661865234),\n",
       " ('yikes', 0.4785458743572235),\n",
       " ('chart', 0.47815006971359253),\n",
       " ('ghetto', 0.4774448275566101)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(\"boring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('frizemedia', 0.43397533893585205),\n",
       " ('tkdl', 0.4317244291305542),\n",
       " ('familyvacay', 0.4214758276939392),\n",
       " ('disneyhotel', 0.4201451539993286),\n",
       " ('collectibles', 0.4172070324420929),\n",
       " ('twdc', 0.4154548943042755),\n",
       " ('disneyattractions', 0.4117432236671448),\n",
       " ('disneyaulani', 0.41010499000549316),\n",
       " ('disneystudios', 0.40937477350234985),\n",
       " ('instadisneyland', 0.40762388706207275)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v.wv.most_similar(\"disney\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v[word].reshape((1, size))\n",
    "            count += 1.\n",
    "        except KeyError: # handling the case where the token is not in vocabulary\n",
    "                         \n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "wordvec_arrays = np.zeros((len(tokenized_tweet), 6000))\n",
    "\n",
    "for i in range(len(tokenized_tweet)):\n",
    "    wordvec_arrays[i,:] = word_vector(tokenized_tweet[i], 6000)\n",
    "\n",
    "wordvec_df = pd.concat([df[['hash_count', 'emoji_count', 'anger','anticipation','disgust','fear',\n",
    "                                                       'joy', 'sadness', 'surprise', 'trust', 'punc_count',\n",
    "                                                       'tweet_len','cap_count']].reset_index(drop=True), \n",
    "           pd.DataFrame(wordvec_arrays)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_count</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>...</th>\n",
       "      <th>5990</th>\n",
       "      <th>5991</th>\n",
       "      <th>5992</th>\n",
       "      <th>5993</th>\n",
       "      <th>5994</th>\n",
       "      <th>5995</th>\n",
       "      <th>5996</th>\n",
       "      <th>5997</th>\n",
       "      <th>5998</th>\n",
       "      <th>5999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012626</td>\n",
       "      <td>0.021376</td>\n",
       "      <td>-0.035375</td>\n",
       "      <td>-0.011598</td>\n",
       "      <td>-0.052767</td>\n",
       "      <td>-0.019092</td>\n",
       "      <td>0.030323</td>\n",
       "      <td>0.021295</td>\n",
       "      <td>-0.012347</td>\n",
       "      <td>-0.062186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019872</td>\n",
       "      <td>0.022338</td>\n",
       "      <td>-0.064997</td>\n",
       "      <td>-0.006185</td>\n",
       "      <td>-0.045894</td>\n",
       "      <td>-0.017409</td>\n",
       "      <td>-0.031949</td>\n",
       "      <td>-0.006251</td>\n",
       "      <td>-0.048054</td>\n",
       "      <td>-0.059388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013231</td>\n",
       "      <td>0.066739</td>\n",
       "      <td>-0.037446</td>\n",
       "      <td>-0.027242</td>\n",
       "      <td>-0.011407</td>\n",
       "      <td>-0.040673</td>\n",
       "      <td>-0.021769</td>\n",
       "      <td>-0.016141</td>\n",
       "      <td>-0.035358</td>\n",
       "      <td>-0.044636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>0.076972</td>\n",
       "      <td>-0.069938</td>\n",
       "      <td>-0.016650</td>\n",
       "      <td>-0.031137</td>\n",
       "      <td>-0.019091</td>\n",
       "      <td>-0.023551</td>\n",
       "      <td>0.019347</td>\n",
       "      <td>-0.054032</td>\n",
       "      <td>-0.010281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059492</td>\n",
       "      <td>0.029682</td>\n",
       "      <td>-0.021310</td>\n",
       "      <td>0.016606</td>\n",
       "      <td>-0.001956</td>\n",
       "      <td>-0.053888</td>\n",
       "      <td>-0.049531</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>-0.034105</td>\n",
       "      <td>-0.071249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87505</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.042045</td>\n",
       "      <td>-0.041691</td>\n",
       "      <td>-0.013512</td>\n",
       "      <td>-0.022923</td>\n",
       "      <td>-0.019002</td>\n",
       "      <td>0.008835</td>\n",
       "      <td>0.012429</td>\n",
       "      <td>-0.050287</td>\n",
       "      <td>-0.027899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87506</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042470</td>\n",
       "      <td>0.023806</td>\n",
       "      <td>0.016434</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>-0.064327</td>\n",
       "      <td>-0.006179</td>\n",
       "      <td>-0.038079</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.025956</td>\n",
       "      <td>-0.083662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87507</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065764</td>\n",
       "      <td>-0.002539</td>\n",
       "      <td>-0.028478</td>\n",
       "      <td>0.038716</td>\n",
       "      <td>0.022798</td>\n",
       "      <td>-0.147807</td>\n",
       "      <td>0.012323</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.011335</td>\n",
       "      <td>-0.070302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87508</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045438</td>\n",
       "      <td>0.017635</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>-0.016274</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>-0.033321</td>\n",
       "      <td>-0.003469</td>\n",
       "      <td>0.014469</td>\n",
       "      <td>-0.046864</td>\n",
       "      <td>-0.050268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87509</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047866</td>\n",
       "      <td>0.030095</td>\n",
       "      <td>0.019994</td>\n",
       "      <td>0.018602</td>\n",
       "      <td>0.012206</td>\n",
       "      <td>-0.012468</td>\n",
       "      <td>-0.010946</td>\n",
       "      <td>-0.028381</td>\n",
       "      <td>0.009911</td>\n",
       "      <td>-0.059160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87510 rows √ó 6013 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hash_count  emoji_count  anger  anticipation  disgust  fear  joy  \\\n",
       "0               1            0      0             0        0     0    0   \n",
       "1               1            0      0             1        0     0    0   \n",
       "2               0            0      0             0        0     0    0   \n",
       "3               1            0      0             0        0     0    0   \n",
       "4               0            0      0             1        0     1    1   \n",
       "...           ...          ...    ...           ...      ...   ...  ...   \n",
       "87505           3            0      0             0        0     0    0   \n",
       "87506           1            1      1             2        0     1    4   \n",
       "87507           0            0      0             0        0     0    0   \n",
       "87508           0            0      0             1        0     0    1   \n",
       "87509           0            2      1             0        1     0    0   \n",
       "\n",
       "       sadness  surprise  trust  ...      5990      5991      5992      5993  \\\n",
       "0            0         0      0  ... -0.012626  0.021376 -0.035375 -0.011598   \n",
       "1            0         0      0  ... -0.019872  0.022338 -0.064997 -0.006185   \n",
       "2            0         0      0  ... -0.013231  0.066739 -0.037446 -0.027242   \n",
       "3            0         0      0  ... -0.000276  0.076972 -0.069938 -0.016650   \n",
       "4            0         0      1  ... -0.059492  0.029682 -0.021310  0.016606   \n",
       "...        ...       ...    ...  ...       ...       ...       ...       ...   \n",
       "87505        0         0      0  ...  0.000276  0.042045 -0.041691 -0.013512   \n",
       "87506        1         4      4  ... -0.042470  0.023806  0.016434  0.000729   \n",
       "87507        0         0      0  ...  0.065764 -0.002539 -0.028478  0.038716   \n",
       "87508        0         0      0  ... -0.045438  0.017635  0.001580 -0.016274   \n",
       "87509        0         0      0  ...  0.047866  0.030095  0.019994  0.018602   \n",
       "\n",
       "           5994      5995      5996      5997      5998      5999  \n",
       "0     -0.052767 -0.019092  0.030323  0.021295 -0.012347 -0.062186  \n",
       "1     -0.045894 -0.017409 -0.031949 -0.006251 -0.048054 -0.059388  \n",
       "2     -0.011407 -0.040673 -0.021769 -0.016141 -0.035358 -0.044636  \n",
       "3     -0.031137 -0.019091 -0.023551  0.019347 -0.054032 -0.010281  \n",
       "4     -0.001956 -0.053888 -0.049531  0.001596 -0.034105 -0.071249  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "87505 -0.022923 -0.019002  0.008835  0.012429 -0.050287 -0.027899  \n",
       "87506 -0.064327 -0.006179 -0.038079  0.033974  0.025956 -0.083662  \n",
       "87507  0.022798 -0.147807  0.012323  0.000423  0.011335 -0.070302  \n",
       "87508  0.011161 -0.033321 -0.003469  0.014469 -0.046864 -0.050268  \n",
       "87509  0.012206 -0.012468 -0.010946 -0.028381  0.009911 -0.059160  \n",
       "\n",
       "[87510 rows x 6013 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training and validation set\n",
    "xtrain_bow, xvalid_bow, ytrain, yvalid = train_test_split(wordvec_df, df['label'],  \n",
    "                                                          random_state=77, \n",
    "                                                          test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 23522), (1, 23522), (2, 23522), (3, 23522), (4, 23522), (5, 23522)]\n"
     ]
    }
   ],
   "source": [
    "#Balance the Data \n",
    "ros = RandomOverSampler(random_state=77) \n",
    "X_resampled_w2vec, y_resampled_w2vec = ros.fit_resample(xtrain_bow.values, ytrain.values)\n",
    "print(sorted(Counter(y_resampled_w2vec).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 5982), (1, 5982), (2, 5982), (3, 5982), (4, 5982), (5, 5982)]\n"
     ]
    }
   ],
   "source": [
    "X_resampled_w2vec_t, y_resampled_w2vec_t = ros.fit_resample(xvalid_bow.values, yvalid.values)\n",
    "print(sorted(Counter(y_resampled_w2vec_t).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 187.561 / Predict time: 5.789 ---- Precision: 0.307 / Recall: 0.269 / Accuracy: 0.269\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "#Instantiate our model \n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=1000, n_jobs=-1)\n",
    "\n",
    "#Model Fit \n",
    "start = time.time()\n",
    "rf.fit(X_resampled_w2vec, y_resampled_w2vec)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = rf.predict(X_resampled_w2vec_t)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_w2vec_t, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_resampled_w2vec_t).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.013440041812033496, 'tweet_len'),\n",
       " (0.012709752733360093, 'hash_count'),\n",
       " (0.008351145987545779, 'joy'),\n",
       " (0.007617788509051857, 'cap_count'),\n",
       " (0.007289074390486536, 'sadness'),\n",
       " (0.007270841433428673, 'punc_count'),\n",
       " (0.007083272958571445, 'fear'),\n",
       " (0.005476012467082672, 'anger'),\n",
       " (0.004971587926797237, 'anticipation'),\n",
       " (0.004663655134884304, 'disgust'),\n",
       " (0.0042407097073909675, 'trust'),\n",
       " (0.0030074068879701503, 'surprise'),\n",
       " (0.0029222317462797797, 'emoji_count'),\n",
       " (0.00023223956377370813, 5374),\n",
       " (0.00022781290631154736, 1516),\n",
       " (0.00022472329630072795, 1626),\n",
       " (0.00022303052532360735, 3291),\n",
       " (0.0002170918237977402, 3744),\n",
       " (0.00021654404155221668, 3903),\n",
       " (0.00021648838819509023, 4898)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest tells our Feature Importances\n",
    "importances = rf.feature_importances_\n",
    "(sorted(zip(importances, xtrain_bow.columns), reverse=True))[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tried Gradientboosting Classifier since Multinomial Bayes doesn't accept negative values \n",
    "\n",
    "#Instantiate our model \n",
    "gb_clf = GradientBoostingClassifier()\n",
    "\n",
    "#Train our Model \n",
    "start = time.time()\n",
    "gb_clf.fit(X_resampled_w2vec, y_resampled_w2vec)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = gb_clf.predict(X_resampled_w2vec_t)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_w2vec_t, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_resampled_w2vec_t).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justin/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time: 120.674 / Predict time: 0.337 ---- Precision: 0.438 / Recall: 0.419 / Accuracy: 0.419\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression \n",
    "\n",
    "#Instantiate our model\n",
    "lr = LogisticRegression(max_iter = 100, solver = 'lbfgs')\n",
    "\n",
    "#Train our Model\n",
    "start = time.time()\n",
    "lr.fit(X_resampled_w2vec, y_resampled_w2vec)\n",
    "end = time.time()\n",
    "fit_time = (end - start)\n",
    "\n",
    "#Model Predict \n",
    "start = time.time()\n",
    "y_pred = lr.predict(X_resampled_w2vec_t)\n",
    "end = time.time()\n",
    "pred_time = (end - start)\n",
    "\n",
    "#Model Scoring \n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_resampled_w2vec_t, y_pred, average='macro')\n",
    "print('Fit time: {} / Predict time: {} ---- Precision: {} / Recall: {} / Accuracy: {}'.format(\n",
    "    round(fit_time, 3), round(pred_time, 3), round(precision, 3), round(recall, 3), round((y_pred==y_resampled_w2vec_t).sum()/len(y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
