{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "import cv2\n",
    "import scipy\n",
    "from PIL import Image\n",
    "import matplotlib.gridspec as gridspec\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras.backend as K\n",
    "#from scipy.interpolate import spline\n",
    "K.set_image_dim_ordering('tf')\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.layers import Input, merge\n",
    "from keras.initializers import RandomNormal\n",
    "K.set_image_dim_ordering('tf')\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True \n",
    "set_session(tf.Session(config=config))\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob('animeface-character-dataset/*/*/*.pn*')\n",
    "\n",
    "print(\"Num_Images: \",len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(5):\n",
    "    img = plt.imread(filenames[i], 0)\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(img.shape)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to normalize image pixels.\n",
    "def norm_img(img):\n",
    "    '''A function to Normalize Images.\n",
    "    Input:\n",
    "        img : Original image as numpy array.\n",
    "    Output: Normailized Image as numpy array\n",
    "    '''\n",
    "    img = (img / 127.5) - 1\n",
    "    return img\n",
    "\n",
    "def denorm_img(img):\n",
    "    '''A function to Denormailze, i.e. recreate image from normalized image\n",
    "    Input:\n",
    "        img : Normalized image as numpy array.\n",
    "    Output: Original Image as numpy array\n",
    "    '''\n",
    "    img = (img + 1) * 127.5\n",
    "    return img.astype(np.uint8) \n",
    "\n",
    "def sample_from_dataset(batch_size, image_shape, data_dir=None):\n",
    "    '''Create a batch of image samples by sampling random images from a data directory.\n",
    "    Resizes the image using image_shape and normalize the images.\n",
    "    Input:\n",
    "        batch_size : Sample size required\n",
    "        image_size : Size that Image should be resized to\n",
    "        data_dir : Path of directory where training images are placed.\n",
    "\n",
    "    Output:\n",
    "        sample : batch of processed images \n",
    "    '''\n",
    "    sample_dim = (batch_size,) + image_shape\n",
    "    sample = np.empty(sample_dim, dtype=np.float32)\n",
    "    all_data_dirlist = list(glob.glob(data_dir))\n",
    "    sample_imgs_paths = np.random.choice(all_data_dirlist,batch_size)\n",
    "    for index,img_filename in enumerate(sample_imgs_paths):\n",
    "        image = Image.open(img_filename)\n",
    "        image = image.resize(image_shape[:-1])\n",
    "        image = image.convert('RGB') \n",
    "        image = np.asarray(image)\n",
    "        image = norm_img(image)\n",
    "        sample[index,...] = image\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_noise(batch_size, noise_shape):\n",
    "    ''' Generates a numpy vector sampled from normal distribution of shape (batch_size,noise_shape)\n",
    "    Input:\n",
    "        batch_size : size of batch\n",
    "        noise_shape: shape of noise vector, normally kept as 100 \n",
    "    Output:a numpy vector sampled from normal distribution of shape (batch_size,noise_shape)     \n",
    "    '''\n",
    "    return np.random.normal(0, 1, size=(batch_size,)+noise_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_normal(noise_shape):\n",
    "    ''' This function takes as input shape of the noise vector and creates the Keras generator    architecture.\n",
    "    '''\n",
    "    kernel_init = 'glorot_uniform'    \n",
    "    gen_input = Input(shape = noise_shape) \n",
    "    \n",
    "    # Transpose 2D conv layer 1. \n",
    "    generator = Conv2DTranspose(filters = 512, kernel_size = (4,4), strides = (1,1), padding = \"valid\", data_format = \"channels_last\", kernel_initializer = kernel_init)(gen_input)\n",
    "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "    \n",
    "    # Transpose 2D conv layer 2.\n",
    "    generator = Conv2DTranspose(filters = 256, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
    "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "    \n",
    "    # Transpose 2D conv layer 3.\n",
    "    generator = Conv2DTranspose(filters = 128, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
    "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "    \n",
    "    # Transpose 2D conv layer 4.\n",
    "    generator = Conv2DTranspose(filters = 64, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
    "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "    \n",
    "    # conv 2D layer 1.\n",
    "    generator = Conv2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
    "    generator = BatchNormalization(momentum = 0.5)(generator)\n",
    "    generator = LeakyReLU(0.2)(generator)\n",
    "    \n",
    "    # Final Transpose 2D conv layer 5 to generate final image. Filter size 3 for 3 image channel\n",
    "    generator = Conv2DTranspose(filters = 3, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(generator)\n",
    "    \n",
    "    # Tanh activation to get final normalized image\n",
    "    generator = Activation('tanh')(generator)\n",
    "    \n",
    "    # defining the optimizer and compiling the generator model.\n",
    "    gen_opt = Adam(lr=0.00015, beta_1=0.5)\n",
    "    generator_model = Model(input = gen_input, output = generator)\n",
    "    generator_model.compile(loss='binary_crossentropy', optimizer=gen_opt, metrics=['accuracy'])\n",
    "    generator_model.summary()\n",
    "    return generator_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disc_normal(image_shape=(64,64,3)):\n",
    "    dropout_prob = 0.4\n",
    "    kernel_init = 'glorot_uniform'\n",
    "    dis_input = Input(shape = image_shape)\n",
    "    \n",
    "    # Conv layer 1:\n",
    "    discriminator = Conv2D(filters = 64, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(dis_input)\n",
    "    discriminator = LeakyReLU(0.2)(discriminator)\n",
    "    # Conv layer 2:\n",
    "    discriminator = Conv2D(filters = 128, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(discriminator)\n",
    "    discriminator = BatchNormalization(momentum = 0.5)(discriminator)\n",
    "    discriminator = LeakyReLU(0.2)(discriminator)\n",
    "    # Conv layer 3:   \n",
    "    discriminator = Conv2D(filters = 256, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(discriminator)\n",
    "    discriminator = BatchNormalization(momentum = 0.5)(discriminator)\n",
    "    discriminator = LeakyReLU(0.2)(discriminator)\n",
    "    # Conv layer 4:\n",
    "    discriminator = Conv2D(filters = 512, kernel_size = (4,4), strides = (2,2), padding = \"same\", data_format = \"channels_last\", kernel_initializer = kernel_init)(discriminator)\n",
    "    discriminator = BatchNormalization(momentum = 0.5)(discriminator)\n",
    "    discriminator = LeakyReLU(0.2)(discriminator)#discriminator = MaxPooling2D(pool_size=(2, 2))(discriminator)\n",
    "    # Flatten\n",
    "    discriminator = Flatten()(discriminator)\n",
    "    # Dense Layer\n",
    "    discriminator = Dense(1)(discriminator)\n",
    "    # Sigmoid Activation\n",
    "    discriminator = Activation('sigmoid')(discriminator)\n",
    "    # Optimizer and Compiling model\n",
    "    dis_opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    discriminator_model = Model(input = dis_input, output = discriminator)\n",
    "    discriminator_model.compile(loss='binary_crossentropy', optimizer=dis_opt, metrics=['accuracy'])\n",
    "    discriminator_model.summary()\n",
    "    return discriminator_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of noise vector to be input to the Generator\n",
    "noise_shape = (1,1,100)\n",
    "# Number of steps for training. num_epochs = num_steps*batch_size/data_size\n",
    "num_steps = 2000\n",
    "# batch size for training.\n",
    "batch_size = 64\n",
    "# Location to save images and logs \n",
    "img_save_dir = \"images/\"\n",
    "# Image size to reshape to\n",
    "image_shape = (64,64,3)\n",
    "# Location of data directory\n",
    "data_dir = \"animeface-character-dataset/*/*/*.pn*\"\n",
    "# set up log and save directories\n",
    "log_dir = img_save_dir\n",
    "save_model_dir = img_save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img_batch(img_batch,img_save_dir):\n",
    "    '''Takes as input a image batch and a img_save_dir and saves 16 images from the batch in a 4x4 grid in the img_save_dir\n",
    "    '''\n",
    "    plt.figure(figsize=(16,16))\n",
    "    gs1 = gridspec.GridSpec(4, 4)\n",
    "    gs1.update(wspace=0, hspace=0)\n",
    "    rand_indices = np.random.choice(img_batch.shape[0],16,replace=False)\n",
    "    for i in range(16):\n",
    "        ax1 = plt.subplot(gs1[i])\n",
    "        ax1.set_aspect('equal')\n",
    "        rand_index = rand_indices[i]\n",
    "        image = img_batch[rand_index, :,:,:]\n",
    "        fig = plt.imshow(denorm_img(image))\n",
    "        plt.axis('off')\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(img_save_dir,bbox_inches='tight',pad_inches=0)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = get_disc_normal(image_shape)\n",
    "generator = get_gen_normal(noise_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(generator, to_file='gen_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(discriminator, to_file='dis_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "\n",
    "# Optimizer for the GAN\n",
    "opt = Adam(lr=0.00015, beta_1=0.5) #same as generator\n",
    "# Input to the generator\n",
    "gen_inp = Input(shape=noise_shape)\n",
    "\n",
    "GAN_inp = generator(gen_inp)\n",
    "GAN_opt = discriminator(GAN_inp)\n",
    "\n",
    "# Final GAN\n",
    "gan = Model(input = gen_inp, output = GAN_opt)\n",
    "gan.compile(loss = 'binary_crossentropy', optimizer = opt, metrics=['accuracy'])\n",
    "\n",
    "plot_model(gan, to_file='gan_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a fixed noise vector to see how the GAN Images transition through time on a fixed noise. \n",
    "fixed_noise = gen_noise(16,noise_shape)\n",
    "\n",
    "# To keep Track of losses\n",
    "avg_disc_fake_loss = []\n",
    "avg_disc_real_loss = []\n",
    "avg_GAN_loss = []\n",
    "\n",
    "# We will run for num_steps iterations\n",
    "for step in range(num_steps): \n",
    "    tot_step = step\n",
    "    print(\"Begin step: \", tot_step)\n",
    "    # to keep track of time per step\n",
    "    step_begin_time = time.time() \n",
    "    \n",
    "    # sample a batch of normalized images from the dataset\n",
    "    real_data_X = sample_from_dataset(batch_size, image_shape, data_dir=data_dir)\n",
    "    \n",
    "    # Genearate noise to send as input to the generator\n",
    "    noise = gen_noise(batch_size,noise_shape)\n",
    "    \n",
    "    # Use generator to create(predict) images\n",
    "    fake_data_X = generator.predict(noise)\n",
    "    \n",
    "    # Save predicted images from the generator every 10th step\n",
    "    if (tot_step % 100) == 0:\n",
    "        step_num = str(tot_step).zfill(4)\n",
    "        save_img_batch(fake_data_X,img_save_dir+step_num+\"_image.png\")\n",
    "    \n",
    "    # Create the labels for real and fake data. We don't give exact ones and zeros but add a small amount of noise. This is an important GAN training trick\n",
    "    real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
    "    fake_data_Y = np.random.random_sample(batch_size)*0.2\n",
    "        \n",
    "    # train the discriminator using data and labels\n",
    "\n",
    "    discriminator.trainable = True\n",
    "    generator.trainable = False\n",
    "\n",
    "    # Training Discriminator seperately on real data\n",
    "    dis_metrics_real = discriminator.train_on_batch(real_data_X,real_data_Y) \n",
    "    # training Discriminator seperately on fake data\n",
    "    dis_metrics_fake = discriminator.train_on_batch(fake_data_X,fake_data_Y) \n",
    "    \n",
    "    print(\"Disc: real loss: %f fake loss: %f\" % (dis_metrics_real[0], dis_metrics_fake[0]))\n",
    "    \n",
    "    # Save the losses to plot later\n",
    "    avg_disc_fake_loss.append(dis_metrics_fake[0])\n",
    "    avg_disc_real_loss.append(dis_metrics_real[0])\n",
    "    \n",
    "    # Train the generator using a random vector of noise and its labels (1's with noise)\n",
    "    generator.trainable = True\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    GAN_X = gen_noise(batch_size,noise_shape)\n",
    "    GAN_Y = real_data_Y\n",
    "   \n",
    "    gan_metrics = gan.train_on_batch(GAN_X,GAN_Y)\n",
    "    print(\"GAN loss: %f\" % (gan_metrics[0]))\n",
    "    \n",
    "    # Log results by opening a file in append mode\n",
    "    text_file = open(log_dir+\"\\\\training_log.txt\", \"a\")\n",
    "    text_file.write(\"Step: %d Disc: real loss: %f fake loss: %f GAN loss: %f\\n\" % (tot_step, dis_metrics_real[0], dis_metrics_fake[0],gan_metrics[0]))\n",
    "    text_file.close()\n",
    "\n",
    "    # save GAN loss to plot later\n",
    "    avg_GAN_loss.append(gan_metrics[0])\n",
    "            \n",
    "    end_time = time.time()\n",
    "    diff_time = int(end_time - step_begin_time)\n",
    "    print(\"Step %d completed. Time took: %s secs.\" % (tot_step, diff_time))\n",
    "    \n",
    "    # save model at every 500 steps\n",
    "    if ((tot_step+1) % 500) == 0:\n",
    "        print(\"-----------------------------------------------------------------\")\n",
    "        print(\"Average Disc_fake loss: %f\" % (np.mean(avg_disc_fake_loss))) \n",
    "        print(\"Average Disc_real loss: %f\" % (np.mean(avg_disc_real_loss))) \n",
    "        print(\"Average GAN loss: %f\" % (np.mean(avg_GAN_loss)))\n",
    "        print(\"-----------------------------------------------------------------\")\n",
    "        discriminator.trainable = False\n",
    "        generator.trainable = False\n",
    "        # predict on fixed_noise\n",
    "        fixed_noise_generate = generator.predict(noise)\n",
    "        step_num = str(tot_step).zfill(4)\n",
    "        save_img_batch(fixed_noise_generate,img_save_dir+step_num+\"fixed_image.png\")\n",
    "        generator.save(save_model_dir+str(tot_step)+\"_GENERATOR_weights_and_arch.hdf5\")\n",
    "        discriminator.save(save_model_dir+str(tot_step)+\"_DISCRIMINATOR_weights_and_arch.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(generator, save_dir):\n",
    "    noise = gen_noise(batch_size,noise_shape)\n",
    "    fake_data_X = generator.predict(noise)\n",
    "    print(\"Displaying generated images\")\n",
    "    plt.figure(figsize=(16,16))\n",
    "    gs1 = gridspec.GridSpec(4, 4)\n",
    "    gs1.update(wspace=0, hspace=0)\n",
    "    rand_indices = np.random.choice(fake_data_X.shape[0],16,replace=False)\n",
    "    for i in range(16):\n",
    "        ax1 = plt.subplot(gs1[i])\n",
    "        ax1.set_aspect('equal')\n",
    "        rand_index = rand_indices[i]\n",
    "        image = fake_data_X[rand_index, :,:,:]\n",
    "        fig = plt.imshow(denorm_img(image))\n",
    "        plt.axis('off')\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_dir+str(time.time())+\"_GENERATEDimage.png\",bbox_inches='tight',pad_inches=0)\n",
    "    plt.show()\n",
    "\n",
    "generate_images(generator, img_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_real_loss = np.array(avg_disc_real_loss)\n",
    "disc_fake_loss = np.array(avg_disc_fake_loss)\n",
    "GAN_loss = np.array(avg_GAN_loss)\n",
    "\n",
    "# Plot the losses vs training steps\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(range(0,num_steps), disc_real_loss, label=\"Discriminator Loss - Real\")\n",
    "plt.plot(range(0,num_steps), disc_fake_loss, label=\"Discriminator Loss - Fake\")\n",
    "plt.plot(range(0,num_steps), GAN_loss, label=\"Generator Loss\")\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('GAN Loss')\n",
    "plt.grid(True)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating GIF from PNGs\n",
    "import imageio\n",
    "# create a list of PNGs\n",
    "generated_images = [img_save_dir+str(x).zfill(4)+\"_image.png\" for x in range(0,num_steps,100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for filename in generated_images:\n",
    "    images.append(imageio.imread(filename))\n",
    "\n",
    "imageio.mimsave(img_save_dir+'movie.gif', images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "with open(\"images/movie.gif\",'rb') as f:\n",
    "    display(Image(data=f.read(), format='png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
